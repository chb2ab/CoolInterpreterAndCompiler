Crispin Bernier
chb2ab
pa3

	I implemented my parser in Python using the PLY package. I began by reading in the token list output by the lexer into my own custom lexer, this is done in gentoks.py. My custom lexer generates tokens by popping them off of a list of tokens that it has stored in memory. I did this because the PLY package requires a lexer to be passed in for the parser to work. The next step was to write out the CFG definition, this is done in main.py. The example parser provided in the PLY documentation was helpful for formatting these definitions properly. The most difficult parts of writing the CFG were including the optional statements and the * and + operations. I handled optional statements by including two versions of a definition, one with the optional statement and one without. For example the 'let' definition has 2 optional statements in it so I had to make 4 definitions for 'let', 2 for each optional statement. I handled the * and + operations by having separate nonterminals that are recursively defined to include expressions of arbitrary length. For example the 'let' statement has a * operation which is handled by defining a new nonterminal designed to handle the possibility of an arbitrary length statement.

	After defining the grammar the parser generator did the hard work of implementing the grammar and parsing the input. The parser returned an AST so the only step left was to serialize the AST. The AST was serialized using the pre-order traversal described in the assignment. This code is in cerealize.py. There were 4 main types a node could have, a program, a class, a feature, a formal, or an expression. Based on the type there were also different subtypes that a node could be, and the assignment described the format for outputting each possible subtype. Outputting a node meant recursively outputting its children, so serializing the root node meant serializing the entire tree.

	The parser was tested on all the cool code I had available to me as well as custom testcases that I made, so having a shell script to automatically test the parser was very helpful to me. The good.cl testcase I made tests many corner cases in the cool syntax. For example good.cl tries to separate expressions across as many lines as possible, which is done because it is necessary for the parser to output the correct line number for an expression. good.cl also tests the different types of dispatch, multiple classes, assignment statements, operator precedence, and other basic cool constructs. bad.cl is a negative testcase which tests the error reporting of the parser. The error in this file is an incorrect nesting of parentheses that spans multiple lines in an assignment statement. I chose this error because it spreads the expression across multiple lines and makes it hard to determine what line number to output in the error message. Outputting the correct line number in error statements was the hardest error for me to fix so it was important for me to test it thoroughly.